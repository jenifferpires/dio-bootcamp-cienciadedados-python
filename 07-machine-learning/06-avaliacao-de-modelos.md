# ğŸ“ AvaliaÃ§Ã£o de Modelos em Machine Learning. 

ApÃ³s treinar um modelo de Machine Learning, Ã© fundamental **avaliar seu desempenho**.  
A avaliaÃ§Ã£o permite entender se o modelo estÃ¡ aprendendo corretamente, se generaliza bem para novos dados e se Ã© confiÃ¡vel para uso real.

Sem avaliaÃ§Ã£o adequada, um modelo pode parecer bom, mas falhar gravemente na prÃ¡tica.

---

## ğŸ¯ Objetivo deste mÃ³dulo:  

Ao final deste conteÃºdo, vocÃª serÃ¡ capaz de:

- Entender por que a avaliaÃ§Ã£o de modelos Ã© essencial.  
- Diferenciar mÃ©tricas para classificaÃ§Ã£o e regressÃ£o.
- Interpretar resultados corretamente.  
- Identificar overfitting e underfitting.  
- Aplicar boas prÃ¡ticas de validaÃ§Ã£o.  

---

## ğŸ§  Por que avaliar modelos?

Avaliar um modelo serve para responder perguntas como:

- O modelo generaliza bem para dados novos?
- Ele estÃ¡ errando muito?
- EstÃ¡ aprendendo padrÃµes reais ou apenas decorando os dados?
- Qual modelo performa melhor para o problema?

ğŸ“Œ **Treinar sem avaliar Ã© como dirigir sem painel.**

---

## ğŸ§ª Tipos de divisÃ£o dos dados.  

### ğŸ”¹ Treino e Teste:  

A base Ã© dividida em dois conjuntos:

- **Treino:** usado para aprender os padrÃµes.  
- **Teste:** usado apenas para avaliaÃ§Ã£o final.  

```text
Treino â†’ aprendizado  
Teste â†’ avaliaÃ§Ã£o
```
### ğŸ”¹ Treino, ValidaÃ§Ã£o e Teste:  

Usado em cenÃ¡rios mais robustos:

- **Treino**: aprendizado.  
- **ValidaÃ§Ã£o**: ajuste de parÃ¢metros.  
- **Teste**: avaliaÃ§Ã£o final.  
---

## ğŸ“Š AvaliaÃ§Ã£o de modelos de classificaÃ§Ã£o. 
#### ğŸ¯ AcurÃ¡cia: 

Percentual de previsÃµes corretas.

ğŸ“Œ Boa quando as classes estÃ£o balanceadas.

---

#### ğŸ¯ PrecisÃ£o:  

Entre os positivos previstos, quantos estÃ£o corretos?

ğŸ“Œ Importante quando falsos positivos sÃ£o crÃ­ticos.

---

### ğŸ¯ Recall (Sensibilidade):  

Entre os positivos reais, quantos o modelo identificou?

ğŸ“Œ Importante quando falsos negativos sÃ£o crÃ­ticos.

---

### ğŸ¯ F1-Score:  

MÃ©dia harmÃ´nica entre precisÃ£o e recall.

ğŸ“Œ Ideal para dados desbalanceados.

---

### ğŸ¯ Matriz de ConfusÃ£o:  

Mostra erros e acertos de forma detalhada.
```text
Verdadeiros Positivos | Falsos Positivos
Falsos Negativos      | Verdadeiros Negativos
```
---

### ğŸ“‰ AvaliaÃ§Ã£o de modelos de regressÃ£o:  
ğŸ”¹ MAE (Erro Absoluto MÃ©dio)

MÃ©dia dos erros absolutos.

---

ğŸ”¹ MSE (Erro QuadrÃ¡tico MÃ©dio)

Penaliza erros maiores.

---

ğŸ”¹ RMSE

Raiz quadrada do MSE, mais interpretÃ¡vel.

---

ğŸ”¹ RÂ² (Coeficiente de DeterminaÃ§Ã£o)

Indica quanto da variabilidade dos dados o modelo explica.

---

### ğŸ§ª Exemplo prÃ¡tico em Python:  
```python
from sklearn.metrics import accuracy_score, confusion_matrix

accuracy = accuracy_score(y_test, y_pred)
matriz = confusion_matrix(y_test, y_pred)

print(accuracy)
print(matriz)
```

### âš ï¸ Erros comuns:  

âŒ Avaliar o modelo com dados de treino.   

âŒ Usar apenas uma mÃ©trica.  

âŒ Ignorar desbalanceamento de classes.  

âŒ Comparar modelos com mÃ©tricas diferentes.  

âŒ NÃ£o validar resultados visualmente.  

### âœ… Boas prÃ¡ticas:  

âœ”ï¸ Separar corretamente treino e teste.  
âœ”ï¸ Escolher mÃ©tricas adequadas ao problema.  
âœ”ï¸ Avaliar mais de uma mÃ©trica.  
âœ”ï¸ Analisar erros, nÃ£o sÃ³ acertos.  
âœ”ï¸ Documentar resultados e decisÃµes.  

### ğŸŒ ConexÃ£o com o mundo real.  

A avaliaÃ§Ã£o de modelos Ã© crÃ­tica em:

Sistemas de crÃ©dito.  
DiagnÃ³stico mÃ©dico.  
DetecÃ§Ã£o de fraudes.  
RecomendaÃ§Ã£o de produtos.  
Tomada de decisÃ£o automatizada.  

Modelos mal avaliados podem gerar impactos reais e prejuÃ­zos.

### ğŸ§¾ ConclusÃ£o:  

Avaliar modelos Ã© tÃ£o importante quanto treinÃ¡-los.
Uma boa avaliaÃ§Ã£o garante confiabilidade, transparÃªncia e qualidade no uso de Machine Learning.  

â¡ï¸ No prÃ³ximo conteÃºdo, avanÃ§aremos para boas prÃ¡ticas e erros comuns em ML, consolidando todo o aprendizado do mÃ³dulo.  


